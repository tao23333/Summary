# 生成标签

> `lable = torch.randint(high=100, size=(10,1)).cuda()`
>
> - 原型：torch.randint(low=0, high, size)                   # size:(N,1)，表示生成N个样本的标签
>   - 生成形状为size的Tensor，其中每个元素取值为[0,100)之间的整数  （表示100个类）



---



# FC权重（the last）

> - 定义：`self.weight = torch.nn.Parameter(torch.FloatTensor(out_features, in_features))`
>   
>   - Parameter将一个不可训练的Tensor转换为可以训练的类型parameter，并且在参数优化时可以进行优化
>   
> - 初始化：`torch.nn.init.xavier_uniform_(self.weight)`
>   - 使之服从均匀分布
>   - 补：`torch.nn.init.xavier_normal_()` # 服从正态分布
>   
> - 求权重矩阵中属于某些类的权重向量
>
>   ```python
>   label = torch.Tensor([1, 0, 2, 1])
>   print(label)
>   print(label.long())
>   weight = torch.randn((3, 2), requires_grad=True)
>   print('weight:', weight)
>   print(weight.detach()[label.long()])
>   print(weight.detach()[label.long()].size()) 
>   ```
>
>   ![2021-03-01_160840](相关代码.assets/2021-03-01_160840.png) 



---



# 文件的打开与关闭

打开如下文件并读取内容：

![2021-03-01_220943](相关代码.assets/2021-03-01_220943.png) 



- > ```python
  >     with open(r'C:\Users\Administrator\Desktop\test\list.txt') as f:
  >         # read()函数返回一个整个文件内容(每行后含有'\n')组成的字符串
  >         # splitlines()将整个字符串按行'\n'分割，每行(不含结尾'\n')作为list的一个元素
  >         img_label_list = f.read().splitlines()
  >     print(img_label_list)
  > ```
  >
  > ![2021-03-01_221043](相关代码.assets/2021-03-01_221043.png) 
  >
  > - 不能使用`f.readlines()`，其虽然将每行作为list的一个元素，但包含了每行结尾的'\n'
  > - 使用with 方式打开文件不用显示关闭文件，默认只读

- > 使用：`f = open(r'C:\Users\Administrator\Desktop\test\list.txt')`
  >
  > - f的方法和上面with方法中的f对象一样；默认只读
  > - 使用完需要显式`f.close()`关闭文件

## 向文件中写入（pandas操作）：

- 写入csv文件：

```python
import pandas as pd

with open(data_file, 'w') as f:
    # 房子数量 进门的小路是什么 价格
    f.write('NumRooms,Alley,Price\n')   # 注意 \n 的添加
    f.write('NA,Pave,127500\n')
    f.write('2,NA,106000\n')
    f.write('4,NA,178000\n')
```

- 读取数据，操作丢失数据，转为Tensor

```python
data = pd.read_csv('data/house_tiny.csv')
print(data) # data类型为 DataFrame类型
# print(type(data))

# 为了处理丢失的数据, 可以将存在缺失的行(样本)直接丢弃, 也可以进行插值, 删除
inputs, outpout = data.iloc[:, 0:2], data.iloc[:, 2]  # index location
inputs = inputs.fillna(inputs.mean()) # 将缺失部分,用该列未缺失部分的均值代替
print(inputs)

# 对于inputs中的 Alley字段的 NAN,我们可以将其视为一个类别
inputs = pd.get_dummies(inputs, dummy_na=True)
print(inputs)

# torch.Tensor() 默认dtype为float32,其不能在初始时显明指定dtype; 不可能传入标量
# torch.tensor() 默认dtype为float64,其可以在初始时显明指定dtype; 可以传入标量
# 由于使用float32计算快于float64,深度学习一般使用float32
x, y = torch.Tensor(inputs.values), torch.tensor(outpout.values, dtype=torch.float32)
print(x, y)
# print(x.dtype, y.dtype)
```



---

# torch.nn.functional 

> ```python
> import torch.nn.functional as F
> 
> - F.normalize(x): 若x为向量，则对其进行L2归一化；若x为矩阵，则将每一行视为一个向量，对每个向量进                     行L2归一化   [x,y]  -> [x/sprt(x^2+y^2),y/sqrt(x^2+y^2)]
> - F.linear(x, weight, bias=None): y = x * weight^T(矩阵乘法) + bias
> ```
>
> 



----



#  torch

- torch.zeros(shape)

  - > one_hot = torch.zeros(cosine.size(), device='cuda')   # 若想使得结果在GPU上，必须添加device属性
    >
    > one_hot.scatter_(1, label.view(-1, 1).long(), 1)   # 完成标签的One-Hot编码 
    >
    > - 若label内容都为torch.int类型，则不用加long()方法

- torch.zeros_like(x)

  - > 参数为具体的数据，若该数据在GPU上，则产生的同样形状的 零Tensor仍在GPU上

- torch.sum(input,dim=,keepdim=)

  - > 矩阵的shape为2个维度，[row, column]，其中其一个元素对应dim=0, 第二个元素对应dim=1
    >
    > 如果为RGB图片的3个维度，则shape中元素依次对应dim=0,1,2
    >
    > 
    >
    > 对矩阵(==dim=0代表竖直方向，dim=1代表水平方向==)使用：
    >
    > - 在使用torch.sum()时如果指定dim=0，则结果的形状为[column]
    > - 在使用torch.sum()时如果指定dim=1，则结果的形状为[row]
    > - 如果没有指定dim，则形状为一个标量（所有元素求和）
    >
    > 关于keepdim属性：
    >
    > - 矩阵中，指定某个dim，则结果中该维度对应的维度消失。
    > - 如果将keepdim设置为True(默认False)，则该维度不会消失，转变为1；结果还是一个矩阵

- torch.diag(input,diagonal=0,out=None)

  - > 如果input为一个1D张量(向量)，则返回以该张量为对角线的2D方阵
    >
    > 如果input为一个2D张量(矩阵)，则返回以该矩阵的对角线组成的1D张量

  - diagonal = 0：主对角线

  - diagonal > 0：主对角线之上

  - diagonal < 0：主对角线之下

  - > 求每个样本所对应的cos值：`cos = torch.diag(cosine.mm(one_hot.t()))`
    >
    > - 设2个样本，3个类，则由 cosine = F.linear(F.normalize(input), F.normalize(weight))得到 2*3的矩阵
    > - one_hot.t()为标签的独热编码矩阵的转置，形状为 3*2
    > - mm()为矩阵的乘法，矩阵相乘后结果为2*2，对角线恰好为每个样本所对应的cos值

- torch.where(条件, a, b)

  - 根据条件合并两个Tensor，若条件满足，使用a中对应元素，若条件不满足，使用b中元素

  - > c = torch.where(条件, a, b)  # 条件为Tensor，形状与a,b相同；内容为bool
    >
    > - 若两个Tensor形状相同，内容均为bool值，则两个Tensor直接可以使用& | 表示逻辑运算
  
- torch.cat( , dim)

  - > ```python
    >   feature_list = [] 
    >   batch_feature = torch.randn((2, 3), requires_grad=True).cuda()
    >   batch_feature2 = torch.randn((2, 3), requires_grad=True).cuda()
    >   batch_feature3 = torch.randn((4, 3), requires_grad=False).cuda()
    > 
    >   feature_list.append(batch_feature)
    >   feature_list.append(batch_feature2)
    >   feature_list.append(batch_feature3.detach()
    >   print('feature_list:', feature_list)  # [ [2,3], [2,3], [4,3]]
    >   
    >   features = torch.cat(feature_list, dim=0)
    >   print('features:', features)  # [2+2+4,3]
    >   
    > ```
    >
    > ![2021-03-01_131104](相关代码.assets/2021-03-01_131104.png)
    >
    > ![2021-03-01_132250](相关代码.assets/2021-03-01_132250.png)
  
  - > ```python
    > label_list = []
    > label = torch.Tensor([1, 2])
    > label2 = torch.Tensor([0, 1])
    > 
    >  label_list.append(label)
    >  label_list.append(label2)
    >  print('label_list:', label_list)  # [ [2], [2]]
    >  labels = torch.cat(label_list, dim=0)
    >  print('labels', labels)  # [2+2]
    > ```
    >
    > ![2021-03-01_132954](相关代码.assets/2021-03-01_132954.png) 
  
  - > ```python
    > # 快速合并两个Tensor
    > features = torch.randn((5, 3))
    > t = torch.randn((2, 3), requires_grad=True)
    > print(features)  # [5,3]
    > print(t) # [2,3]
    > k = torch.cat((features, t.detach()), dim=0)
    > print('k:', k)  # [5+2,3]
    > ```
    >
    > ![2021-03-01_133320](相关代码.assets/2021-03-01_133320.png)
  
- torch.chunk()

  - > 作用：将Tensor切分成N份，放到一个元组中
    >
    > ```python
    > features = torch.randn((5, 3))
    > print(features.chunk(2, 0))  # ([3,3],[2,3]) 等价于 torch.chunk(features,2,dim=0)
    > print(type(features.chunk(2, 0))) # tuple
    > print(list(features.chunk(2, 0)))  # [[3,3],[2,3]]
    > print(type(list(features.chunk(2, 0)))) # list
    > ```
    >
    > ![2021-03-01_155011](相关代码.assets/2021-03-01_155011.png) 

- torch.norm(,dim)

  - > 作用：求Tensor的二范数，结果为一个1D张量
    >
    > ```python
    > features = torch.randn((2, 2))
    > norm = torch.norm(features, dim=1)  # dim=1表示按行求范数
    > print(norm)  # tensor([0.5043, 0.8691])
    > ```

- torch.dot() / torch.mv() / torch.mm() / torch.matmul()

  - > ```python
    > # 向量点积, 矩阵*向量, 矩阵*矩阵
    > 
    > a = torch.Tensor([1, 2, 3])
    > b = torch.Tensor([2, 3, 4])
    > c = torch.Tensor([[1, 2, 3], [4, 5, 6]])
    > d = torch.Tensor([[1, 2, 3], [4, 5, 6]])
    > print(torch.dot(a, b))   # dot只用来做两个向量之间的点积: 按元素相乘再相加
    > print(c, a)
    > print(torch.mv(c, a)) # mv用来做 矩阵 * 向量 = 向量 [矩阵的每一行与该向量做点积]
    > # 向量 * 矩阵 = 向量 ，这个操作用torch.matmul()做  (2,) * (2, 3) = (3,)
    > 
    > print(c.mv(a))
    > print(torch.mm(c, d.t())) # mm用来做 矩阵 * 矩阵 = 矩阵
    > 
    > # 两个矩阵按元素相乘 称为 哈达玛积(Hadamard product)
    > # 数学符号为: 圆圈中心一个点
    > ```
    >
  
- torch.sequeeze() / torch.unsequeeze()

  - sequeeze()用来对Tensor降维；unsequeeze()升维

    ```python
    a = torch.arange(6).reshape(1, 2, 3)
    print(a)
    print(a.squeeze(0))  # 将第0维削减   shape:(2,3)
    print(a.unsequeeze(0))  # 升维度   shape:(1,2,3)
    ```

    

---

# numpy

## 从正态分布取样

> `data = np.random.normal(loc=0, scale=1,size=100)`
>
> - 从均值为0，方差为1的正态分布中取100个样本



## 高斯混合模型使用

> ```python
> from sklearn.mixture import GaussianMixture
> 
> # 生成数据
> data1 = np.random.normal(loc=-0.2, scale=0.2, size=70000)
> data2 = np.random.normal(loc=0.7, scale=0.2, size=70000)
> data = np.hstack((data1, data2)) # 将两组数组组合在一起
> 
> gmm = GaussianMixture(n_components=2) #定义模型(该模型由2个高斯模型叠加而成)
> gmm.fit(data.reshape(-1, 1)) #根据数据拟合模型参数
> means = gmm.means_  # 两个高斯模型分别的均值
> means = np.sort(means, axis=0)  # 排序
> print('最大的均值:', means[1][0])
> ```



## 保存数据

> `np.save(os.path.join(hist_save_dir, 'data'), data)`
>
> - 生成一个扩展名为npy的文件
> - 该文件的读取：`data = np.load(路径)`



## 从指定范围获取N个随机数

> 使用 `np.random.choice(a, size=1, replace=True)`
>
> - a：整数或者1D数组（list,tuple,ndarray,...），整数a表示范围在[0, a)之间。
> - size=1：默认只获取一个随机数
> - replace=True：可以获取相同的数字

- > ```python
  > k = np.random.choice(2) #在[0, 2)之间获取一个整数  ，不是0 就是1。可以用作50%概率条件
  > k = np.random.choice([1,2,3,5],2,replace=False) # 在这几个数字中获取两个，且两个数字要不同
  > ```

---





# OS

## 生成目录

> ```python
> import os
> from datetime import datetime
> 
> # 使用os.path.join将两个字符串拼接，形成目录路径(join会在两个字符串之间用‘\’连接)
> # .\histogrampics\20200226_225240
> hist_save_dir = os.path.join('.\histogrampics',datetime.now().strftime('%Y%m%d_%H%M%S'))
> 
> if not os.path.exists(hist_save_dir):  如果目录不存在就生成该目录
> 	os.makedirs(hist_save_dir)
> ```
>
> - os.makedirs()：可生成任何层次的目录
> - os.mkdir()：只能生成一层目录
>   - 如过histogrampics目录不存在，则相当于生成两级目录，此时使用mkdir将会报错
>
> 关于 `os.path.join(a,b)`补充：
>
> - 若b这个路径前缀为1个字符+1个冒号，即类似`C:	`，则a这个不经不会拼接到b上，拼接结果为b本身
>
> 补：
>
> - 如果不存在就生成某目录的另一种实现方式（不需if）
>
>   `os.makedirs(os.path.join('.', 'data'), exist_ok=True)`  如果当前目录下不存在data目录就生成他
>
> 



##  os.listdir('路径')

> 作用：将该目录下一级的目录名，文件名放到list返回，若该目录为空，则返回 []。用来根据数据集构建其对应的list文件
>
> ```python
> path = r'./mxnet'
> path2 = r't'    # t为一个空目录
> print(os.listdir(path))   # ['test.py','sd']
> print(os.listdir(path2))  # []
> if os.listdir(path2):   # [] 用作判断条件等价于False
>     print(123)
> ```
>
> ![2021-03-01_165109](相关代码.assets/2021-03-01_165109.png) 





---

# matplotlib

- 保存图片：`plt.savefig(os.path.join(目录路径, 'pic.jpg'))` `plt.close()`
- 绘制直方图：`plt.hist(data, bins=200)`  `plt.show()`
  - bins表示将data按照值大小平均分成200个组，分别统计处于每个组范围内的频数



# collections

- deque    

  - > deque为双端队列
    >
    > 定义：`q = deque(maxlen=10)`   # 则该队列最多容纳10个元素，满10个之后，先进先出
    >
    > 将numpy内容添加到deque：`q.extend(a)`
    >
    > - ```python
    >   from collections import deque
    >   import numpy as np
    >   
    >   q = deque(maxlen=4)
    >   a = np.array([1,2,3])
    >   b = np.array([4,5,6])
    >   q.extend(a)  # [1,2,3]
    >   q.extend(b)  # [3,4,5,6]
    >   ```
    >
    > deque -> numpy：`n = np.array(q)`

  - deque数据可以直接使用matplotlib

    - `plt.hist(q, bins=5)`  `plt.show()`



---


# 人脸训练集
## 人脸对齐

> ```python
> import cv2
> import os
> import numpy as np
> from skimage import transform as trans
> 
> 
> def insightpreprocess(landmark, img, img_name, dist_dir):
>     tform = trans.SimilarityTransform()
>     src = np.array([
>         [30.2946, 51.6963],
>         [65.5318, 51.5014],
>         [48.0252, 71.7366],
>         [33.5493, 92.3655],
>         [62.7299, 92.2041]], dtype=np.float32)
>     src[:, 0] += 8.0  # src是针对112*96的
>     tform.estimate(landmark, src)
>     M = tform.params[0:2, :]
>     image_size = (112, 112)
>     img = cv2.warpAffine(img, M, (image_size[1], image_size[0]), borderValue=0.0)
>     # cv2.imshow('Video', img)
>     cv2.imwrite(os.path.join(dist_dir, img_name), img)
>     # cv2.waitKey(0)
> 
> 
> 
> if __name__ == '__main__':
>     # 路径中不要有中文，否则会报错
>     # 报错原因还有: 图片名称是否含有非法字符
>     dist_dir = r'E:\wangpanLoad\ca-aligned_112'   # 保存对齐后的图片路径
>     landmark_txt = r'E:\wangpanLoad\CA_landmarks'  # 存放landmark文件路径
>     origin_dir = r'E:\wangpanLoad\ca_images\images' # 存放原图片的路径
> 
>     if not os.path.exists(dist_dir):
>         os.makedirs(dist_dir)
> 
>     img_names = os.listdir(origin_dir)
> 
>     count = 0
>     # 将图片一张张对齐，写入目标目录中
>     for img_name in img_names:
>         if count % 1 == 0:  # 跳过CPLFW 下的images(源)文件夹中txt文件，如果不是这种情况改成%1即可
>             img = cv2.imread(os.path.join(origin_dir, img_name))
>             # 图片名称为 wsj ,对应的landmark.txt文件名为：wsj._5loc_attri.txt,也可能是 wsj.jjp._5loc_attri.txt
>             landmark = np.loadtxt(os.path.join(landmark_txt, ".".join(img_name.split('.')[:-1])+'_5loc_attri.txt'))
>             insightpreprocess(landmark, img, img_name, dist_dir)
>         count = count + 1
>     # landmark = np.loadtxt(r't\Barbora_Strycov_2_5loc_attri.txt')
>     # img = cv2.imread(r'image\Barbora_Strycov_2.jpg')
>     # insightpreprocess(landmark, img, 'Barbora_Strycov_2.jpg', 't')  # 图片对应的landmark及图片本身
> ```
>
> 



---



## 训练集产生list.txt文件

> ```python
> import os
> 
> def dataset_list(dataset_path,dataset_list):
>      label_list = os.listdir(dataset_path)
>      f=open(dataset_list, 'w')
>      k=0
>      for i in label_list:
>          label_path=os.path.join(dataset_path,i)
>          if os.listdir(label_path):
>             image_list=os.listdir(label_path)
>             for j in image_list:
>                 image_path=os.path.join(label_path, j)
>                 f.write(image_path+'  '+str(k)+'\n')
>          k=k+1
>      f.close()
> 
> if __name__=='__main__':
>     dataset = r'E:\wangpanLoad\umd_images'
>     list = r'E:\wangpanLoad\umd_faces_list.txt'
> 
>     # print(os.listdir(dataset))
>     dataset_list(dataset, list)
> 
> ```
>
> 



## rec to image And bin to image

> ```python
> #!/usr/bin/env python
> # encoding: utf-8
> '''
> @desc: For AgeDB-30 and CFP-FP test dataset, we use the mxnet binary file provided by insightface, this is the tool to restore
>        the aligned images from mxnet binary file.
>        You should install a mxnet-cpu first, just do 'pip install mxnet -i 豆瓣镜像网址' is ok.
> '''
> 
> from PIL import Image
> import cv2
> import os
> import pickle
> import mxnet as mx
> from tqdm import tqdm
> 
> '''
> For train dataset, insightface provide a mxnet .rec file, just install a mxnet-cpu for extract images
> '''
> 
> def load_mx_rec(rec_path, save_path):
>     if not os.path.exists(save_path):
>         os.makedirs(save_path)
> 
>     imgrec = mx.recordio.MXIndexedRecordIO(os.path.join(rec_path, 'train.idx'), os.path.join(rec_path, 'train.rec'), 'r')
>     img_info = imgrec.read_idx(0)
>     header,_ = mx.recordio.unpack(img_info)
>     max_idx = int(header.label[0])
>     for idx in tqdm(range(1,max_idx)):
>         img_info = imgrec.read_idx(idx)
>         header, img = mx.recordio.unpack_img(img_info)
>         label = int(header.label)
>         #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
>         #img = Image.fromarray(img)
>         label_path = os.path.join(save_path, str(label).zfill(6))
>         if not os.path.exists(label_path):
>             os.makedirs(label_path)
>         #img.save(os.path.join(label_path, str(idx).zfill(8) + '.jpg'), quality=95)
>         cv2.imwrite(os.path.join(label_path, str(idx).zfill(8) + '.jpg'), img)
> 
> 
> def load_image_from_bin(bin_path, save_dir):
>     if not os.path.exists(save_dir):
>         os.makedirs(save_dir)
>     file = open(os.path.join(save_dir, '../', 'lfw_pair.txt'), 'w')
>     bins, issame_list = pickle.load(open(bin_path, 'rb'), encoding='bytes')
>     for idx in tqdm(range(len(bins))):
>         _bin = bins[idx]
>         img = mx.image.imdecode(_bin).asnumpy()
>         img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
>         cv2.imwrite(os.path.join(save_dir, str(idx+1).zfill(5)+'.jpg'), img)
>         if idx % 2 == 0:
>             label = 1 if issame_list[idx//2] == True else -1
>             file.write(str(idx+1).zfill(5) + '.jpg' + ' ' + str(idx+2).zfill(5) +'.jpg' + ' ' + str(label) + '\n')
> 
> 
> if __name__ == '__main__':
> 
>     # 从lfw.bin agedb_30.bin cfp_fp.bin提取图片(112*112)和对应的pairs.txt测试文件
>     bin_path = r'E:\wangpanLoad\faces_umd\faces_umd\lfw.bin'
>     save_dir = r'E:\wangpanLoad\faces_umd\faces_umd\lfw'
>     load_image_from_bin(bin_path, save_dir)
>     
>     # 从rec和对应的idx文件提取训练集图片并产生标签列表文件
>     # rec_path = r'E:\wangpanLoad\faces_umd\faces_umd'
>     # save_path = r'E:\wangpanLoad\umd_images'
>     # load_mx_rec(rec_path, save_path)
> 
> 
> ```
>
> 



---

# 人脸测试集

## pairs.txt内容格式转换

对于CALFW和CPLFW的测试文件，内容为：

![2021-03-11_164244](相关代码.assets/2021-03-11_164244.png) 

![2021-03-11_164258](相关代码.assets/2021-03-11_164258.png) 



其中，第一行和第二行为一对，第三行第四行为1对。

若想使得每对在同一行上，使用如下代码：

> ```python
> import os
> import numpy as np
> 
> if __name__ == '__main__':
>     with open(r"C:\Users\Administrator\Desktop\pairs_CPLFW.txt") as f:
>         pairs = f.read().splitlines()
>     print(pairs)
>     with open(r"C:\Users\Administrator\Desktop\pairs_CPLFW_changed.txt", "w") as f2:
>         count = 0
>         for i in pairs:
>             if count % 2 == 0:  # 偶数行取前半个
>                 left_img = i.split()[0]
>             else:  # 奇数行取整行，并与上行结果拼接，最终结果成为新文件的一行
>                 final = left_img + " " + i + "\n"
>                 f2.write(final)
>             count = count + 1
> ```
>
> 





---

# argparse参数模块

## 一般步骤

> - 导入模块 ：`import argpase`
>
> - 创建参数解析器对象 ：`parser = argparse.ArgumentParser('description='test')`
>
>   - `description`参数可有可无
>
> - 向解析器对象中添加参数：
>
>   `parser.add_argument("--root", default='/t/r', type=str, help='path')`
>
>   - 第一个参数"--root"，表明添加的参数名为root
>   - default表示该参数的默认值
>   - type表示该参数的类型
>   - help用来放置一些该参数所表示的含义或者参数的所有可选值
>
> - 解析参数：`args = parser.parse_args()`
>
>   - 以上添加到参数解析器中的参数即可作为args对象的属性使用
>
> - 使用参数：
>
>   - `print(args.root)`  # /t/r



# 矩阵求导

![2021-04-13_215033](相关代码.assets/2021-04-13_215033.png) 

![2021-04-13_215057](相关代码.assets/2021-04-13_215057.png) 

![2021-04-13_215148](相关代码.assets/2021-04-13_215148.png) 



![2021-04-13_215217](相关代码.assets/2021-04-13_215217.png) 



![2021-04-13_215235](相关代码.assets/2021-04-13_215235.png) 



![2021-04-13_215538](相关代码.assets/2021-04-13_215538.png) 



## 计算图与反向传播

<img src="相关代码.assets/2021-04-14_132359.png" alt="2021-04-14_132359" style="zoom:67%;" />  



<img src="相关代码.assets/2021-04-14_133111.png" alt="2021-04-14_133111" style="zoom: 67%;" /> 

 

<img src="相关代码.assets/2021-04-14_133815.png" alt="2021-04-14_133815" style="zoom:67%;" /> 

 <img src="相关代码.assets/2021-04-14_134120.png" alt="2021-04-14_134120" style="zoom:67%;" /> 



<img src="相关代码.assets/2021-04-14_134554.png" alt="2021-04-14_134554" style="zoom:67%;" /> 

<img src="相关代码.assets/2021-04-14_134741.png" alt="2021-04-14_134741" style="zoom:67%;" /> 



 <img src="相关代码.assets/2021-04-14_134838.png" alt="2021-04-14_134838" style="zoom:67%;" />  

 

